# import json
# import subprocess
# import time
# from pathlib import Path
# import requests

# def wait_for_tor_proxy_ready(max_retries=10, delay_sec=10):
#     for attempt in range(1, max_retries + 1):
#         try:
#             print(f"[Tor Check] ({attempt}/{max_retries})")
#             proxies = {
#                 'http': 'socks5h://127.0.0.1:9050',
#                 'https': 'socks5h://127.0.0.1:9050'
#             }
#             res = requests.get('https://check.torproject.org/', proxies=proxies, timeout=5)
#             if res.status_code == 200 and "Congratulations" in res.text:
#                 print("[âœ“] Tor Proxy Ready!")
#                 return
#         except Exception:
#             print("[Waiting for Tor Proxy...]")
#         time.sleep(delay_sec)
#     print("[âœ–] Tor Proxy not ready after retries. Exiting.")
#     exit(1)

# def run_crawler():
#     json_path = Path("/app/downloads/onion_list.json")

#     if not json_path.exists() or json_path.stat().st_size == 0:
#         print("âŒ onion_list.json íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
#         return

#     with open(json_path, "r") as f:
#         fqdn_list = json.load(f)

#     for entry in fqdn_list:
#         fqdn = entry.get("fqdn")
#         if not fqdn:
#             continue

#         outfile = f"/app/downloads/{fqdn.replace('.', '_').replace('/', '')}.html"
#         print(f"ğŸ“¥ í¬ë¡¤ë§ ëŒ€ìƒ: {fqdn}")
#         curl_cmd = [
#             "curl",
#             "--fail",
#             "--socks5-hostname", "127.0.0.1:9050",
#             "--connect-timeout", "10",
#             "--max-time", "30",
#             "-L",
#             f"http://{fqdn}",
#             "-o", outfile
#         ]

#         print(f"ğŸ‘‰ ì‹¤í–‰: {' '.join(curl_cmd)}")
#         try:
#             subprocess.run(curl_cmd, check=True)
#             print(f"âœ… ì €ì¥ë¨: {outfile}")
#         except subprocess.CalledProcessError:
#             print(f"âŒ curl ì‹¤íŒ¨: {fqdn}")

# if __name__ == "__main__":
#     wait_for_tor_proxy_ready()  
#     while True:
#         print("\ncurl í¬ë¡¤ëŸ¬ ì‹¤í–‰")
#         run_crawler()
#         print("curl í¬ë¡¤ë§ ì™„ë£Œ, ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ëŒ€ê¸°")
#         time.sleep(10 * 60)

import json
import subprocess
import time
from pathlib import Path
import requests

def wait_for_tor_proxy_ready(max_retries=10, delay_sec=10):
    for attempt in range(1, max_retries + 1):
        try:
            print(f"[Tor Check] ({attempt}/{max_retries})")
            proxies = {
                'http': 'socks5h://127.0.0.1:9050',
                'https': 'socks5h://127.0.0.1:9050'
            }
            res = requests.get('https://check.torproject.org/', proxies=proxies, timeout=5)
            if res.status_code == 200 and "Congratulations" in res.text:
                print("[âœ“] Tor Proxy Ready!")
                return
        except Exception:
            print("[Waiting for Tor Proxy...]")
        time.sleep(delay_sec)
    print("[âœ–] Tor Proxy not ready after retries. Exiting.")
    exit(1)

def run_crawler():
    json_path = Path("/app/downloads/onion_list.json")

    if not json_path.exists() or json_path.stat().st_size == 0:
        print("âŒ onion_list.json íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    with open(json_path, "r") as f:
        fqdn_list = json.load(f)

    if not fqdn_list:
        print("âŒ FQDN ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    for entry in fqdn_list:
        fqdn = entry.get("fqdn")
        if not fqdn:
            continue

        outfile = f"/app/downloads/{fqdn.replace('.', '_').replace('/', '')}.html"
        print(f"ğŸ“¥ í¬ë¡¤ë§ ëŒ€ìƒ: {fqdn}")
        curl_cmd = [
            "curl",
            "--fail",
            "--socks5-hostname", "127.0.0.1:9050",
            "--connect-timeout", "10",
            "--max-time", "30",
            "-L",
            f"http://{fqdn}",
            "-o", outfile
        ]

        print(f"ğŸ‘‰ ì‹¤í–‰: {' '.join(curl_cmd)}")
        try:
            subprocess.run(curl_cmd, check=True)
            print(f"âœ… ì €ì¥ë¨: {outfile}")
        except subprocess.CalledProcessError:
            print(f"âŒ curl ì‹¤íŒ¨: {fqdn}")

if __name__ == "__main__":
    wait_for_tor_proxy_ready()
    print("\ncurl í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì‹œì‘")
    run_crawler()
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ, curl-crawler ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit(0)
